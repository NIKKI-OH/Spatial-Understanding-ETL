import json
import requests
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from io import BytesIO

# ==========================================
# 0. å‡†å¤‡å…¨æ¨¡æ€æ ·æœ¬ (All-in-One Data)
# æˆ‘ä»¬æ‰‹åŠ¨ä¸ºä¸åŒçš„å›¾ç‰‡åˆ†é…ä¸åŒçš„ä»»åŠ¡ç±»å‹
# ==========================================
REAL_SAMPLES = [
    {
        # ä»»åŠ¡ 1: ç‰©ä½“æ£€æµ‹ (Detection)
        "id": "task_bbox_cat",
        "url": "http://images.cocodataset.org/val2017/000000039769.jpg",
        "task_type": "detection",
        "label": "cat",
        "data": {
            "bbox": [14, 3, 310, 477] # [x, y, w, h]
        },
        "instruction": "Detect the cat."
    },
    {
        # ä»»åŠ¡ 2: è½¨è¿¹é¢„æµ‹ (Trajectory) - æ¨¡æ‹Ÿæ»‘é›ªè·¯å¾„
        "id": "task_traj_skier",
        "url": "http://images.cocodataset.org/val2017/000000000785.jpg",
        "task_type": "trajectory",
        "label": "skier_path",
        "data": {
            # æ¨¡æ‹Ÿä¸€ä¸²ç‚¹ï¼šä»å¤´é¡¶æ»‘ä¸‹æ¥çš„è½¨è¿¹ [[x,y], [x,y]...]
            "points": [[250, 20], [260, 100], [280, 200], [300, 300], [220, 350]]
        },
        "instruction": "Predict the future trajectory of the skier."
    },
    {
        # ä»»åŠ¡ 3: å¯ä¾›æ€§/æ“ä½œç‚¹ (Affordance) - æ¨¡æ‹Ÿæœºå™¨äººåº”è¯¥çœ‹å‘å“ªé‡Œ
        "id": "task_affordance_sign",
        "url": "http://images.cocodataset.org/val2017/000000000724.jpg",
        "task_type": "affordance",
        "label": "stop_sign_center",
        "data": {
            # å…³æ³¨ç‚¹/æŠ“å–ç‚¹ [x, y]
            "point": [343, 202] 
        },
        "instruction": "Where is the center of the stop sign for interaction?"
    }
]

# ==========================================
# 1. æ ¸å¿ƒé€»è¾‘ï¼šé€šç”¨ ETL æµæ°´çº¿
# ==========================================
def download_image(url):
    print(f"ğŸ“¥ ä¸‹è½½ä¸­: {url} ...")
    try:
        response = requests.get(url, timeout=10)
        return Image.open(BytesIO(response.content))
    except:
        return None

def normalize_coords(coords, w, h, type="bbox"):
    """ä¸‡èƒ½å½’ä¸€åŒ–å‡½æ•°ï¼šæ”¯æŒ bbox, point, trajectory"""
    if type == "bbox":
        x, y, bw, bh = coords
        return [round(x/w, 3), round(y/h, 3), round((x+bw)/w, 3), round((y+bh)/h, 3)]
    elif type == "point":
        return [round(coords[0]/w, 3), round(coords[1]/h, 3)]
    elif type == "trajectory":
        return [[round(p[0]/w, 3), round(p[1]/h, 3)] for p in coords]

def run_multimodal_pipeline():
    print("ğŸš€ å¯åŠ¨å…¨æ¨¡æ€ç©ºé—´ç†è§£æµæ°´çº¿ (BBox + Traj + Affordance)...")
    
    unified_data = []
    
    for item in REAL_SAMPLES:
        image = download_image(item["url"])
        if not image: continue
        w, h = image.size
        
        # --- 1. æ„å»ºç»Ÿä¸€æ ¼å¼ (Unified Schema) ---
        entry = {
            "id": item["id"],
            "source": "coco_simulated",
            "task_type": item["task_type"],
            "media": {"image_size": [w, h], "url": item["url"]},
            "spatial_annotations": [],
            "conversations": []
        }
        
        # --- 2. æ ¹æ®ä¸åŒä»»åŠ¡ç±»å‹å¤„ç†æ•°æ® ---
        raw_data = item["data"]
        
        if item["task_type"] == "detection":
            norm_box = normalize_coords(raw_data["bbox"], w, h, "bbox")
            entry["spatial_annotations"].append({
                "type": "bbox", "value": norm_box, "label": item["label"]
            })
            gpt_resp = f"Found at <box>{norm_box}</box>."

        elif item["task_type"] == "trajectory":
            norm_traj = normalize_coords(raw_data["points"], w, h, "trajectory")
            entry["spatial_annotations"].append({
                "type": "trajectory", "value": norm_traj, "label": item["label"]
            })
            gpt_resp = f"Trajectory path: <traj>{norm_traj}</traj>."

        elif item["task_type"] == "affordance":
            norm_point = normalize_coords(raw_data["point"], w, h, "point")
            entry["spatial_annotations"].append({
                "type": "point", "value": norm_point, "label": item["label"]
            })
            gpt_resp = f"Interact at point: <point>{norm_point}</point>."

        # å¡«å…¥å¯¹è¯
        entry["conversations"] = [
            {"from": "human", "value": item["instruction"]},
            {"from": "gpt", "value": gpt_resp}
        ]
        
        unified_data.append(entry)
        
        # --- 3. å¯è§†åŒ–éªŒè¯ (ç”»å‡ºä¸åŒçš„å½¢çŠ¶) ---
        visualize_task(image, item, f"verify_{item['task_type']}.png")

    # ä¿å­˜ JSONL
    with open("unified_multimodal_data.jsonl", "w") as f:
        for d in unified_data:
            f.write(json.dumps(d) + "\n")
    print("âœ… å…¨æ¨¡æ€æ•°æ®å¤„ç†å®Œæˆï¼")

# ==========================================
# 2. å¯è§†åŒ–æ¨¡å— (æ ¹æ®ä»»åŠ¡ç”»ä¸åŒçš„å›¾)
# ==========================================
def visualize_task(image, item, save_name):
    plt.figure(figsize=(8, 8))
    plt.imshow(image)
    ax = plt.gca()
    
    data = item["data"]
    task = item["task_type"]
    
    if task == "detection":
        # ç”»æ¡†
        x, y, w, h = data["bbox"]
        rect = patches.Rectangle((x, y), w, h, linewidth=3, edgecolor='#00FF00', facecolor='none')
        ax.add_patch(rect)
        plt.title(f"Task: Detection (BBox) - {item['label']}")
        
    elif task == "trajectory":
        # ç”»çº¿ (è½¨è¿¹)
        points = data["points"]
        # è§£å‹ x å’Œ y åæ ‡åˆ—è¡¨
        xs = [p[0] for p in points]
        ys = [p[1] for p in points]
        # ç”»çº¢è‰²çš„è½¨è¿¹çº¿ï¼Œå¸¦ç‚¹
        plt.plot(xs, ys, color='red', linewidth=4, marker='o', markersize=8)
        plt.title(f"Task: Trajectory (Path) - {item['label']}")
        
    elif task == "affordance":
        # ç”»ç‚¹ (çƒ­åŠ›ç‚¹/æ“ä½œç‚¹)
        x, y = data["point"]
        # ç”»ä¸€ä¸ªåŠé€æ˜çš„åœ†
        circle = patches.Circle((x, y), radius=20, color='blue', alpha=0.6)
        ax.add_patch(circle)
        # ç”»ä¸­å¿ƒåå­—
        plt.plot(x, y, 'w+', markersize=10)
        plt.title(f"Task: Affordance (Interaction Point) - {item['label']}")

    plt.axis('off')
    plt.savefig(save_name, bbox_inches='tight')
    plt.close()

if __name__ == "__main__":
    run_multimodal_pipeline()
